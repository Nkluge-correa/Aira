{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making a Closed Domain Chatbot Via Text Classification\n",
    "\n",
    "Return to the [index](https://github.com/Nkluge-correa/Aira-EXPERT).\n",
    "\n",
    "**In this notebook, we train the `Bi-LSTM` and `decoder-only transformer` version of Ai.ra.**\n",
    "\n",
    "## Data & Preprocessing\n",
    "\n",
    "**This code is preparing data for a language model. Specifically, it is creating a training and testing dataset for a text classification task.**\n",
    "\n",
    "**First, the code opens a file named \"_data/tags_pt.txt_\" using the `with` statement and reads its content. It then processes each line of the file, extracting the text and label of each entry. The text is added to a list called `X` and the label to another list called `Y`.**\n",
    "\n",
    "**Next, the code defines some parameters for the language model, such as the size of the vocabulary, the size of the embedding layer, and the maximum sequence length. It then imports the TensorFlow library and creates a `TextVectorization` layer. This layer converts text into a sequence of integers and pads/truncates the sequences to ensure that they have the same length.**\n",
    "\n",
    "**The code then adapts the `TextVectorization` layer to the `X` data to learn the vocabulary and transform the data. The vocabulary is saved to a file named \"_aira/vocabulary_pt_.txt\".**\n",
    "\n",
    "**Finally, the code splits the data into training and testing sets using `train_test_split` from scikit-learn. It encodes the text data using the `TextVectorization` layer and one-hot encodes the labels using `to_categorical` from Keras. The resulting training and testing data are stored in variables named `x_train`, `x_test`, `y_train`, and `y_test`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "language = \"pt\" # \"bilingual\", \"pt\", or \"en\"\n",
    "\n",
    "with open(f'data/tags_{language}.txt', encoding='utf-8') as fp:\n",
    "    X = [[' '.join(line.strip().split(' ')[:-1])] for line in fp]\n",
    "    fp.close()\n",
    "\n",
    "with open(f'data/tags_{language}.txt', encoding='utf-8') as fp:\n",
    "    Y = [int(line.strip().split(' ')[-1]) for line in fp]\n",
    "    fp.close()\n",
    "\n",
    "vocab_size = 2000 #4000 for bilingual or 2000 for english or portuguese\n",
    "embed_size = 256\n",
    "sequence_length = 10\n",
    "\n",
    "# Create a vectorization layer and adapt it to the text\n",
    "vectorize_layer = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode='int',\n",
    "    ngrams=3,\n",
    "    output_sequence_length=sequence_length)\n",
    "\n",
    "vectorize_layer.adapt(X)\n",
    "vocabulary = vectorize_layer.get_vocabulary()\n",
    "\n",
    "# Save the vocabulary for later inspection\n",
    "with open(f'aira/vocabulary_{language}.txt', 'w') as fp:\n",
    "    for word in vocabulary:\n",
    "        fp.write(\"%s\\n\" % word)\n",
    "    fp.close()\n",
    "\n",
    "encoded_X = vectorize_layer(X)\n",
    "\n",
    "encoded_X\n",
    "one_hot_encoded_Y = tf.keras.utils.to_categorical(Y)[:,1:]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(encoded_X.numpy(), \n",
    "                                                    one_hot_encoded_Y, \n",
    "                                                    test_size=0.1, \n",
    "                                                    random_state=42)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Bi-LSTM`\n",
    "\n",
    "**This code is defining and training a `Bidirectional Long Short-Term Memory` neural network for text classification.**\n",
    "\n",
    "> **A `BiLSTM` is a type of recurrent neural network (`RNN`) that is commonly used for processing sequential data, such as text or speech. It extends the capabilities of a regular `LSTM` by processing the input sequence in both forward and backward directions, allowing the network to capture dependencies that exist in both directions.**\n",
    "\n",
    "**The model is defined using the Keras functional API. The input layer is defined using `tf.keras.Input`, and the text data is passed through an Embedding layer to create dense word embeddings. The Embedding layer is followed by two Bidirectional LSTM layers with 128 units each. The output of the second LSTM layer is passed through a Dense layer with a softmax activation function, which outputs a probability distribution over the classes.**\n",
    "\n",
    "**The model is compiled using the Adam optimizer, categorical cross-entropy loss function, and categorical accuracy as the evaluation metric.**\n",
    "\n",
    "**The code then defines a list of callbacks to be used during training, including early stopping, model checkpointing, and reducing the learning rate on a plateau.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  2.10.1\n",
      "Eager mode:  True\n",
      "GPU is available\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 10)]              0         \n",
      "                                                                 \n",
      " embedding_5 (Embedding)     (None, 10, 256)           512000    \n",
      "                                                                 \n",
      " bidirectional_6 (Bidirectio  (None, 10, 256)          394240    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_7 (Bidirectio  (None, 256)              394240    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 142)               36494     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,336,974\n",
      "Trainable params: 1,336,974\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "110/110 [==============================] - 16s 52ms/step - loss: 4.8913 - categorical_accuracy: 0.0479 - val_loss: 4.8091 - val_categorical_accuracy: 0.0411 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 2s 20ms/step - loss: 4.2385 - categorical_accuracy: 0.1199 - val_loss: 4.3228 - val_categorical_accuracy: 0.1005 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 2s 19ms/step - loss: 3.2210 - categorical_accuracy: 0.2842 - val_loss: 3.6254 - val_categorical_accuracy: 0.2557 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 2s 19ms/step - loss: 2.2570 - categorical_accuracy: 0.5046 - val_loss: 3.0501 - val_categorical_accuracy: 0.3699 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 2s 18ms/step - loss: 1.4842 - categorical_accuracy: 0.6804 - val_loss: 2.6745 - val_categorical_accuracy: 0.4703 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 2s 19ms/step - loss: 0.9620 - categorical_accuracy: 0.8174 - val_loss: 2.2834 - val_categorical_accuracy: 0.5571 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 2s 19ms/step - loss: 0.5763 - categorical_accuracy: 0.9189 - val_loss: 2.2408 - val_categorical_accuracy: 0.5936 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 2s 18ms/step - loss: 0.3587 - categorical_accuracy: 0.9566 - val_loss: 2.1134 - val_categorical_accuracy: 0.6256 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 2s 19ms/step - loss: 0.2389 - categorical_accuracy: 0.9726 - val_loss: 2.1184 - val_categorical_accuracy: 0.6393 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 2s 22ms/step - loss: 0.1512 - categorical_accuracy: 0.9840 - val_loss: 2.0912 - val_categorical_accuracy: 0.6530 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.1036 - categorical_accuracy: 0.9874 - val_loss: 2.1833 - val_categorical_accuracy: 0.6484 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 2s 22ms/step - loss: 0.1054 - categorical_accuracy: 0.9817 - val_loss: 2.2068 - val_categorical_accuracy: 0.6256 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 2s 22ms/step - loss: 0.0782 - categorical_accuracy: 0.9874 - val_loss: 2.1768 - val_categorical_accuracy: 0.6484 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0558 - categorical_accuracy: 0.9897 - val_loss: 2.1761 - val_categorical_accuracy: 0.6393 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 3s 25ms/step - loss: 0.0443 - categorical_accuracy: 0.9920 - val_loss: 2.1733 - val_categorical_accuracy: 0.6393 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 2s 22ms/step - loss: 0.0396 - categorical_accuracy: 0.9909 - val_loss: 2.1836 - val_categorical_accuracy: 0.6438 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 2s 22ms/step - loss: 0.0375 - categorical_accuracy: 0.9909 - val_loss: 2.1946 - val_categorical_accuracy: 0.6393 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 2s 23ms/step - loss: 0.0330 - categorical_accuracy: 0.9932 - val_loss: 2.1928 - val_categorical_accuracy: 0.6438 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "110/110 [==============================] - 2s 21ms/step - loss: 0.0326 - categorical_accuracy: 0.9897 - val_loss: 2.2183 - val_categorical_accuracy: 0.6393 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "110/110 [==============================] - 2s 22ms/step - loss: 0.0317 - categorical_accuracy: 0.9920 - val_loss: 2.2229 - val_categorical_accuracy: 0.6484 - lr: 0.0010\n",
      "4/4 [==============================] - 4s 30ms/step - loss: 1.7501 - categorical_accuracy: 0.6721\n",
      "Final Loss: 1.8.\n",
      "Final Performance: 67.21 %.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "inputs = tf.keras.Input(shape=(x_train.shape[1],), dtype=\"int32\")\n",
    "\n",
    "embedded_inputs = tf.keras.layers.Embedding(\n",
    "    input_dim=vocab_size, \n",
    "    output_dim=embed_size, \n",
    "    mask_zero=True)(inputs)\n",
    "\n",
    "x = tf.keras.layers.Bidirectional(\n",
    "    tf.keras.layers.LSTM(128, return_sequences=True))(embedded_inputs)\n",
    "x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128))(x)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(142, activation=\"softmax\")(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['categorical_accuracy'])\n",
    "\n",
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")\n",
    "model.summary()\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', \n",
    "                                    patience=10), \n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath=f'aira/Aira_BiLSTM_{language}.keras', \n",
    "                                        monitor='categorical_accuracy', \n",
    "                                        save_best_only=True,),  \n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_categorical_accuracy', \n",
    "                                        factor=0.1, \n",
    "                                        patience=10), \n",
    "]\n",
    "\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          validation_split = 0.2,\n",
    "          epochs=100,\n",
    "          batch_size=8,\n",
    "          verbose=1,\n",
    "          callbacks=callbacks)\n",
    "\n",
    "model = tf.keras.models.load_model(f'aira/Aira_BiLSTM_{language}.keras')\n",
    "test_loss_score, test_acc_score = model.evaluate(x_test, y_test)\n",
    "\n",
    "print(f'Final Loss: {round(test_loss_score, 1)}.')\n",
    "print(f'Final Performance: {round(test_acc_score * 100, 2)} %.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Ensemble Bi-LSTM`\n",
    "\n",
    "**This model is an ensemble of two `BiLSTM` layers, each taking a different input. The two inputs are processed in parallel, and their outputs are concatenated and fed into a final dense layer with a softmax activation function.**\n",
    "\n",
    "> **Ensemble model is a machine learning technique that combines several individual models to improve the performance of the overall system.**\n",
    "\n",
    "**The code begins by importing the required libraries and setting some hyperparameters such as the vocabulary size, sequence length, and embedding size. Then, it defines two input layers `inputs_1` and `inputs_2`, each taking sequences of integers with a variable length. These layers are then passed through separate embedding layers `embedded_inputs_1` and `embedded_inputs_2`, respectively, which convert the input integers into dense vectors of fixed size.**\n",
    "\n",
    "**Next, each embedding layer output is fed into a bidirectional LSTM layer with 128 units, which processes the input sequences in both forward and backward directions to capture both past and future context. The output of the second LSTM layer is then concatenated with the output of the first LSTM layer along the last axis using `tf.keras.layers.concatenate` to produce a single tensor.**\n",
    "\n",
    "**Finally, the concatenated tensor is passed through a dense layer with a softmax activation function that produces class probabilities.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  2.10.1\n",
      "Eager mode:  True\n",
      "GPU is available\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " embedded_inputs_1 (Embedding)  (None, 10, 256)      512000      ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " embedded_inputs_2 (Embedding)  (None, 10, 256)      512000      ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " bidirectional_8 (Bidirectional  (None, 10, 256)     394240      ['embedded_inputs_1[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bidirectional_10 (Bidirectiona  (None, 10, 256)     394240      ['embedded_inputs_2[0][0]']      \n",
      " l)                                                                                               \n",
      "                                                                                                  \n",
      " bidirectional_9 (Bidirectional  (None, 256)         394240      ['bidirectional_8[0][0]']        \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bidirectional_11 (Bidirectiona  (None, 256)         394240      ['bidirectional_10[0][0]']       \n",
      " l)                                                                                               \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 512)          0           ['bidirectional_9[0][0]',        \n",
      "                                                                  'bidirectional_11[0][0]']       \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 142)          72846       ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,673,806\n",
      "Trainable params: 2,673,806\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "110/110 [==============================] - 32s 98ms/step - loss: 4.8603 - categorical_accuracy: 0.0639 - val_loss: 4.6813 - val_categorical_accuracy: 0.0548 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 4s 32ms/step - loss: 3.8392 - categorical_accuracy: 0.2158 - val_loss: 3.6810 - val_categorical_accuracy: 0.2192 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 4s 40ms/step - loss: 2.3356 - categorical_accuracy: 0.5365 - val_loss: 2.7446 - val_categorical_accuracy: 0.4612 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 5s 43ms/step - loss: 1.2540 - categorical_accuracy: 0.7888 - val_loss: 2.3268 - val_categorical_accuracy: 0.5982 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 5s 43ms/step - loss: 0.6916 - categorical_accuracy: 0.9087 - val_loss: 1.8436 - val_categorical_accuracy: 0.6712 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 5s 43ms/step - loss: 0.3508 - categorical_accuracy: 0.9680 - val_loss: 1.7222 - val_categorical_accuracy: 0.7032 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 5s 44ms/step - loss: 0.1915 - categorical_accuracy: 0.9806 - val_loss: 1.6322 - val_categorical_accuracy: 0.7306 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 5s 45ms/step - loss: 0.1055 - categorical_accuracy: 0.9829 - val_loss: 1.6940 - val_categorical_accuracy: 0.6986 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 5s 42ms/step - loss: 0.0738 - categorical_accuracy: 0.9897 - val_loss: 1.7201 - val_categorical_accuracy: 0.7215 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 4s 41ms/step - loss: 0.0600 - categorical_accuracy: 0.9863 - val_loss: 1.7136 - val_categorical_accuracy: 0.7169 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 5s 43ms/step - loss: 0.0430 - categorical_accuracy: 0.9909 - val_loss: 1.7314 - val_categorical_accuracy: 0.7123 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 5s 43ms/step - loss: 0.0356 - categorical_accuracy: 0.9897 - val_loss: 1.7698 - val_categorical_accuracy: 0.7169 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 5s 43ms/step - loss: 0.0323 - categorical_accuracy: 0.9909 - val_loss: 1.7743 - val_categorical_accuracy: 0.7169 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 5s 44ms/step - loss: 0.0314 - categorical_accuracy: 0.9909 - val_loss: 1.7911 - val_categorical_accuracy: 0.7169 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 5s 44ms/step - loss: 0.0291 - categorical_accuracy: 0.9932 - val_loss: 1.7796 - val_categorical_accuracy: 0.7123 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 5s 45ms/step - loss: 0.0262 - categorical_accuracy: 0.9897 - val_loss: 1.7994 - val_categorical_accuracy: 0.7123 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 5s 44ms/step - loss: 0.0259 - categorical_accuracy: 0.9909 - val_loss: 1.7909 - val_categorical_accuracy: 0.7123 - lr: 0.0010\n",
      "4/4 [==============================] - 6s 51ms/step - loss: 1.5895 - categorical_accuracy: 0.7459\n",
      "Final Loss: 1.6.\n",
      "Final Performance: 74.59 %.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "inputs_1= tf.keras.Input(shape=(x_train.shape[1],), dtype=\"int32\",  name='input_1')\n",
    "\n",
    "embedded_inputs_1 = tf.keras.layers.Embedding(\n",
    "    input_dim=vocab_size, \n",
    "    output_dim=embed_size, \n",
    "    mask_zero=True,\n",
    "    name=\"embedded_inputs_1\")(inputs_1)\n",
    "\n",
    "x_1 = tf.keras.layers.Bidirectional(\n",
    "    tf.keras.layers.LSTM(128, return_sequences=True))(embedded_inputs_1)\n",
    "x_1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128))(x_1)\n",
    "\n",
    "inputs_2= tf.keras.Input(shape=(x_train.shape[1],), dtype=\"int32\",  name='input_2')\n",
    "\n",
    "embedded_inputs_2 = tf.keras.layers.Embedding(\n",
    "    input_dim=vocab_size, \n",
    "    output_dim=embed_size, \n",
    "    mask_zero=True,\n",
    "    name=\"embedded_inputs_2\")(inputs_2)\n",
    "\n",
    "x_2 = tf.keras.layers.Bidirectional(\n",
    "    tf.keras.layers.LSTM(128, return_sequences=True))(embedded_inputs_2)\n",
    "x_2 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128))(x_2)\n",
    "\n",
    "concatenated = tf.keras.layers.concatenate([x_1, x_2], axis=-1)\n",
    "outputs = tf.keras.layers.Dense(142, activation=\"softmax\")(concatenated)\n",
    "\n",
    "model = tf.keras.Model([inputs_1, inputs_2], outputs)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['categorical_accuracy'])\n",
    "\n",
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")\n",
    "model.summary()\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', \n",
    "                                    patience=10), \n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath=f'aira/Aira_BiLSTM_ENSEMB_{language}.keras', \n",
    "                                        monitor='categorical_accuracy', \n",
    "                                        save_best_only=True,),  \n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_categorical_accuracy', \n",
    "                                        factor=0.1, \n",
    "                                        patience=10), \n",
    "]\n",
    "\n",
    "model.fit([x_train, x_train],\n",
    "          y_train,\n",
    "          validation_split = 0.2,\n",
    "          epochs=100,\n",
    "          batch_size=8,\n",
    "          verbose=1,\n",
    "          callbacks=callbacks)\n",
    "\n",
    "model = tf.keras.models.load_model(f'aira/Aira_BiLSTM_ENSEMB_{language}.keras')\n",
    "test_loss_score, test_acc_score = model.evaluate([x_test,x_test], y_test)\n",
    "\n",
    "print(f'Final Loss: {round(test_loss_score, 1)}.')\n",
    "print(f'Final Performance: {round(test_acc_score * 100, 2)} %.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Dedocer-Transformer`\n",
    "\n",
    "**The code is implementing a `Transformer` model to perform text classification.**\n",
    "\n",
    "> **`Decoder-only transformers` are a type of transformer architecture that only consists of the decoder module, while omitting the encoder module.**\n",
    "\n",
    "**The first section imports the `PositionalEmbedding` and `TransformerEncoder` classes from the `tblocks` file.**\n",
    "\n",
    "**The input is passed through a `PositionalEmbedding` layer that applies embedding to the input tokens and adds positional information to the embeddings. The output of the `PositionalEmbedding` layer is passed through a `TransformerEncoder` layer that performs multi-head self-attention on the input sequence and then applies dense projections on the concatenated outputs of the attention heads.**\n",
    "\n",
    "**The output of the `TransformerEncoder` layer is passed through a `GlobalMaxPooling1D` layer that performs global max pooling along the temporal axis of the tensor. Then, the output is passed through a `Dropout` layer with a rate of `0.5` to reduce overfitting. Finally, a `Dense` layer with `softmax` activation is used to produce the output probabilities for each of the classes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 10)]              0         \n",
      "                                                                 \n",
      " positional_embedding_1 (Pos  (None, 10, 256)          514560    \n",
      " itionalEmbedding)                                               \n",
      "                                                                 \n",
      " transformer_encoder_1 (Tran  (None, 10, 256)          1841664   \n",
      " sformerEncoder)                                                 \n",
      "                                                                 \n",
      " global_max_pooling1d_1 (Glo  (None, 256)              0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 142)               36494     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,392,718\n",
      "Trainable params: 2,392,718\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Version:  2.10.1\n",
      "Eager mode:  True\n",
      "GPU is available\n",
      "Epoch 1/100\n",
      "110/110 [==============================] - 2s 15ms/step - loss: 6.0836 - categorical_accuracy: 0.0091 - val_loss: 5.1510 - val_categorical_accuracy: 0.0183 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 1s 13ms/step - loss: 5.2066 - categorical_accuracy: 0.0342 - val_loss: 4.4482 - val_categorical_accuracy: 0.1324 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 3.3437 - categorical_accuracy: 0.2968 - val_loss: 2.7178 - val_categorical_accuracy: 0.4566 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 1.3143 - categorical_accuracy: 0.7158 - val_loss: 2.0579 - val_categorical_accuracy: 0.6027 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 1s 13ms/step - loss: 0.6130 - categorical_accuracy: 0.8790 - val_loss: 1.8137 - val_categorical_accuracy: 0.6941 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 1s 14ms/step - loss: 0.3995 - categorical_accuracy: 0.9247 - val_loss: 1.7196 - val_categorical_accuracy: 0.7078 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 1s 14ms/step - loss: 0.1865 - categorical_accuracy: 0.9578 - val_loss: 1.6704 - val_categorical_accuracy: 0.7489 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 1s 13ms/step - loss: 0.1128 - categorical_accuracy: 0.9760 - val_loss: 1.5170 - val_categorical_accuracy: 0.7671 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 1s 14ms/step - loss: 0.1069 - categorical_accuracy: 0.9795 - val_loss: 1.7196 - val_categorical_accuracy: 0.7260 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 1s 13ms/step - loss: 0.0770 - categorical_accuracy: 0.9817 - val_loss: 1.6216 - val_categorical_accuracy: 0.7443 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 1s 13ms/step - loss: 0.1109 - categorical_accuracy: 0.9726 - val_loss: 1.5698 - val_categorical_accuracy: 0.7534 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 0.1262 - categorical_accuracy: 0.9737 - val_loss: 1.6439 - val_categorical_accuracy: 0.7443 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 1s 13ms/step - loss: 0.0561 - categorical_accuracy: 0.9852 - val_loss: 1.5821 - val_categorical_accuracy: 0.7443 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 2s 14ms/step - loss: 0.0432 - categorical_accuracy: 0.9909 - val_loss: 1.6124 - val_categorical_accuracy: 0.7671 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 0.0413 - categorical_accuracy: 0.9909 - val_loss: 1.6212 - val_categorical_accuracy: 0.7626 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 1s 13ms/step - loss: 0.0455 - categorical_accuracy: 0.9897 - val_loss: 1.5956 - val_categorical_accuracy: 0.7626 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 1s 14ms/step - loss: 0.0321 - categorical_accuracy: 0.9920 - val_loss: 1.6087 - val_categorical_accuracy: 0.7580 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 1s 12ms/step - loss: 0.0363 - categorical_accuracy: 0.9909 - val_loss: 1.6089 - val_categorical_accuracy: 0.7626 - lr: 0.0010\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.4659 - categorical_accuracy: 0.7541\n",
      "Final Loss: 1.5.\n",
      "Final Performance: 75.41 %.\n"
     ]
    }
   ],
   "source": [
    "from tblocks import PositionalEmbedding, TransformerEncoder\n",
    "import tensorflow as tf\n",
    "\n",
    "num_heads = 6\n",
    "dense_dim = 512\n",
    "\n",
    "inputs = tf.keras.Input(shape=(x_train.shape[1],), dtype=\"int64\")\n",
    "\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_size)(inputs)\n",
    "x = TransformerEncoder(embed_size, dense_dim, num_heads)(x)\n",
    "x = tf.keras.layers.GlobalMaxPooling1D()(x) \n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(142, activation=\"softmax\")(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "model.compile(optimizer=\"adam\", \n",
    "    loss=\"categorical_crossentropy\", \n",
    "    metrics=[\"categorical_accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', \n",
    "                                    patience=10), \n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath=f'aira/Aira_transformer_{language}.keras', \n",
    "                                        monitor='categorical_accuracy', \n",
    "                                        save_best_only=True,),  \n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_categorical_accuracy', \n",
    "                                        factor=0.1, \n",
    "                                        patience=10), \n",
    "]\n",
    "\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          validation_split = 0.2,\n",
    "          epochs=100,\n",
    "          batch_size=8,\n",
    "          verbose=1,\n",
    "          callbacks=callbacks)\n",
    "\n",
    "model = tf.keras.models.load_model(f\"aira/Aira_transformer_{language}.keras\", \n",
    "                                custom_objects={\"TransformerEncoder\": TransformerEncoder, \n",
    "                                                 \"PositionalEmbedding\": PositionalEmbedding})\n",
    "\n",
    "test_loss_score, test_acc_score = model.evaluate(x_test, y_test)\n",
    "\n",
    "print(f'Final Loss: {round(test_loss_score, 1)}.')\n",
    "print(f'Final Performance: {round(test_acc_score * 100, 2)} %.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Models\n",
    "\n",
    "**Below you can load one of the trained models for inspection.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.load_model(f\"aira/Aira_BiLSTM_ENSEMB_{language}.keras\")\n",
    "\n",
    "# to load the transformer, pass the:\n",
    "#\n",
    "# 'custom_objects={\"TransformerEncoder\": TransformerEncoder, \n",
    "#                   \"PositionalEmbedding\": PositionalEmbedding}' \n",
    "# \n",
    "# argument.\n",
    "\n",
    "with open(f'aira/vocabulary_{language}.txt', encoding='utf-8') as fp:\n",
    "    vocabulary = [line[:-1] for line in fp]\n",
    "    fp.close()\n",
    "\n",
    "with open('data/answers_en.txt', encoding='utf-8') as fp:\n",
    "    answers = [line.strip() for line in fp]\n",
    "    fp.close()\n",
    "\n",
    "\n",
    "vocab_size = 4000 #4000 for bilingual or 2000 for english or portuguese\n",
    "sequence_length = 10\n",
    "\n",
    "text_vectorization = tf.keras.layers.TextVectorization(max_tokens=vocab_size, \n",
    "                                        output_mode=\"int\", \n",
    "                                        ngrams=3,\n",
    "                                        vocabulary=vocabulary,\n",
    "                                        output_sequence_length=sequence_length)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here are some strings/questions to test the trained models.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questions: O que é o problema de Alinhamento?\n",
      "\n",
      "Encoded Sentence: [  2   3 652   2  25   8  35   4 730   1]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Answers: \n",
       "\n",
       "`Outer-alignment`, in the context of Machine Learning, is the **extent to which the specified objective function is aligned with the intended goal of its designers**. This is an intuitive notion, in part because human intentions themselves are not well understood. This is what is usually discussed as the \"_[value alignment](https://intelligence.org/files/ValueLearningProblem.pdf)_\" problem. \n",
       "\n",
       "[Confidence:  95.72 %]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "from IPython.display import Markdown \n",
    "\n",
    "#text = '''what is Interpretability?'''\n",
    "#text = '''What is the problem of alignment?'''\n",
    "#text = '''O que é Interpretabilidade?'''\n",
    "text = '''O que é o problema de Alinhamento?'''\n",
    "#text = '''What is Machine Learning?'''\n",
    "#text = '''O que é Ética das Virtudes?'''\n",
    "#text = '''What is your name?'''\n",
    "#text = '''Qual é o seu nome?'''\n",
    "#text = '''O que é SGD?'''\n",
    "#text = '''What is Stochastic Gradient Descent?'''\n",
    "\n",
    "print(f'Questions: {text}\\n')\n",
    "\n",
    "encoded_sentence = text_vectorization(text.lower()\\\n",
    "                                      .translate(str.maketrans('', '', string.punctuation)))\n",
    "print(f'Encoded Sentence: {encoded_sentence}\\n')\n",
    "\n",
    "INPUT = tf.keras.backend.expand_dims(encoded_sentence, axis=0)\n",
    "\n",
    "preds = model.predict([INPUT,INPUT],verbose=0)[0]\n",
    "output = answers[np.argmax(preds)]\n",
    "\n",
    "display(Markdown(f'Answers: \\n\\n{output} \\n\\n[Confidence: {max(preds) * 100: .2f} %]'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Return to the [index](https://github.com/Nkluge-correa/Aira-EXPERT)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
