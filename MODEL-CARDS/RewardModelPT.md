---
license: apache-2.0
datasets:
- nicholasKluge/reward-aira-dataset
language:
- pt
metrics:
- accuracy
library_name: transformers
pipeline_tag: text-classification
tags:
- reward model
- alignment
- preference model
- RLHF
widget:
- text: "Quem se importa com a Ã©tica da IA? Ã‰ apenas um monte de reclamaÃ§Ãµes sobre o fato de os humanos criarem e usarem IA e reclamarem do que as mÃ¡quinas fazem."
  example_title: Resposta Ruim
- text: "A Ã©tica da IA Ã© importante por vÃ¡rios motivos convincentes:\n\n1.**Impacto social**: As tecnologias de IA estÃ£o se tornando cada vez mais integradas a vÃ¡rios aspectos da sociedade, afetando tudo, desde saÃºde e educaÃ§Ã£o atÃ© finanÃ§as e aplicaÃ§Ã£o da lei. ConsideraÃ§Ãµes Ã©ticas garantem que os sistemas de IA contribuam positivamente para a sociedade e minimizem os possÃ­veis danos.\n\n2. **Vieses e justiÃ§a**: Os sistemas de IA podem herdar vieses presentes nos dados em que sÃ£o treinados, levando a resultados injustos ou discriminatÃ³rios. ConsideraÃ§Ãµes Ã©ticas pressionam pelo desenvolvimento de algoritmos imparciais que tratem todos os indivÃ­duos de forma justa, independentemente de seu histÃ³rico.\n\n3. **TransparÃªncia e responsabilidade**: Muitos sistemas de IA operam como caixas pretas, dificultando a compreensÃ£o de como chegam Ã s suas decisÃµes. As diretrizes Ã©ticas enfatizam a importÃ¢ncia da transparÃªncia, permitindo que os usuÃ¡rios compreendam a lÃ³gica por trÃ¡s dos resultados gerados pela IA e responsabilizando os desenvolvedores por quaisquer consequÃªncias negativas.\n\nEm resumo, a Ã©tica da IA Ã© vital para garantir que a inteligÃªncia artificial beneficie a sociedade, respeitando os direitos humanos fundamentais, a justiÃ§a, a transparÃªncia, a responsabilidade e o bem-estar da humanidade em longo prazo. Ela ajuda a enfrentar os desafios impostos pelo rÃ¡pido avanÃ§o das tecnologias de IA e orienta seu desenvolvimento de forma a se alinhar com nossos valores compartilhados."
  example_title: Resposta Boa
co2_eq_emissions:
  emissions: 0.07
  source: CodeCarbon
  training_type: fine-tuning
  geographical_location: Singapore
  hardware_used: NVIDIA A100-SXM4-40GB
---
# RewardModel (Portuguese)

The RewardModelPT is a [BERT](https://huggingface.co/neuralmind/bert-base-portuguese-cased) model that can be used to score the quality of a completion for a given prompt.

The model was trained with a dataset composed of `prompt`, `prefered_completions`, and `rejected_completions`.

## Details

- **Size:** 109,038,209 parameters
- **Dataset:** [Reward-Aira Dataset](https://huggingface.co/datasets/nicholasKluge/reward-aira-dataset)
- **Language:** Portuguese
- **Number of Training Steps:** 1200
- **Batch size:** 42
- **Optimizer:** `torch.optim.AdamW`
- **Learning Rate:** 5e-5
- **GPU:** 1 NVIDIA A100-SXM4-40GB
- **Emissions:** 0.07 KgCO2 (Singapore)
- **Total Energy Consumption:** 0.16 kWh

This repository has the [source code](https://github.com/Nkluge-correa/Aira) used to train this model.

## Usage

Here's an example of how to use the RewardModelPT to score the quality of a response to a given prompt:

```python
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

tokenizer = AutoTokenizer.from_pretrained("nicholasKluge/RewardModelPT")
rewardModel = AutoModelForSequenceClassification.from_pretrained("nicholasKluge/RewardModelPT")

rewardModel.eval()
rewardModel.to(device)

# Define the question and response
prompt = "Por que a Ã©tica da IA Ã© importante?"

response_good = "A Ã©tica da IA Ã© importante por vÃ¡rios motivos convincentes:\n\n1.**Impacto social**: As tecnologias de IA estÃ£o se tornando cada vez mais integradas a vÃ¡rios aspectos da sociedade, afetando tudo, desde saÃºde e educaÃ§Ã£o atÃ© finanÃ§as e aplicaÃ§Ã£o da lei. ConsideraÃ§Ãµes Ã©ticas garantem que os sistemas de IA contribuam positivamente para a sociedade e minimizem os possÃ­veis danos.\n\n2. **Vieses e justiÃ§a**: Os sistemas de IA podem herdar vieses presentes nos dados em que sÃ£o treinados, levando a resultados injustos ou discriminatÃ³rios. ConsideraÃ§Ãµes Ã©ticas pressionam pelo desenvolvimento de algoritmos imparciais que tratem todos os indivÃ­duos de forma justa, independentemente de seu histÃ³rico.\n\n3. **TransparÃªncia e responsabilidade**: Muitos sistemas de IA operam como caixas pretas, dificultando a compreensÃ£o de como chegam Ã s suas decisÃµes. As diretrizes Ã©ticas enfatizam a importÃ¢ncia da transparÃªncia, permitindo que os usuÃ¡rios compreendam a lÃ³gica por trÃ¡s dos resultados gerados pela IA e responsabilizando os desenvolvedores por quaisquer consequÃªncias negativas.\n\nEm resumo, a Ã©tica da IA Ã© vital para garantir que a inteligÃªncia artificial beneficie a sociedade, respeitando os direitos humanos fundamentais, a justiÃ§a, a transparÃªncia, a responsabilidade e o bem-estar da humanidade em longo prazo. Ela ajuda a enfrentar os desafios impostos pelo rÃ¡pido avanÃ§o das tecnologias de IA e orienta seu desenvolvimento de forma a se alinhar com nossos valores compartilhados."
response_bad = "Quem se importa com a Ã©tica da IA? Ã‰ apenas um monte de reclamaÃ§Ãµes sobre o fato de os humanos criarem e usarem IA e reclamarem do que as mÃ¡quinas fazem."

# Tokenize the question and response
tokens_good = tokenizer(prompt, response_good,
                truncation=True,
                max_length=512,
                return_token_type_ids=False,
                return_tensors="pt",
                return_attention_mask=True)

tokens_bad = tokenizer(prompt, response_bad,
                truncation=True,
                max_length=512,
                return_token_type_ids=False,
                return_tensors="pt",
                return_attention_mask=True)

tokens_good.to(device)
tokens_bad.to(device)

score_good = rewardModel(**tokens_good)[0].item()
score_bad = rewardModel(**tokens_bad)[0].item()

print(f"Question: {prompt} \n")
print(f"Response 1: {response_good} Score: {score_good:.3f}")
print(f"Response 2: {response_bad} Score: {score_bad:.3f}")
```

This will output the following:

```markdown
>>> Question: Por que a Ã©tica da IA Ã© importante? 

>>>Response 1: A Ã©tica da IA Ã© importante por vÃ¡rios motivos convincentes:

1.**Impacto social**: As tecnologias de IA estÃ£o se tornando cada vez mais integradas a vÃ¡rios aspectos da sociedade, afetando tudo,
desde saÃºde e educaÃ§Ã£o atÃ© finanÃ§as e aplicaÃ§Ã£o da lei. ConsideraÃ§Ãµes Ã©ticas garantem que os sistemas de IA contribuam positivamente
para a sociedade e minimizem os possÃ­veis danos.

2. **Vieses e justiÃ§a**: Os sistemas de IA podem herdar vieses presentes nos dados em que sÃ£o treinados, levando a resultados
injustos ou discriminatÃ³rios. ConsideraÃ§Ãµes Ã©ticas pressionam pelo desenvolvimento de algoritmos imparciais que tratem todos os
indivÃ­duos de forma justa, independentemente de seu histÃ³rico.

3. **TransparÃªncia e responsabilidade**: Muitos sistemas de IA operam como caixas pretas, dificultando a compreensÃ£o de como
chegam Ã s suas decisÃµes. As diretrizes Ã©ticas enfatizam a importÃ¢ncia da transparÃªncia, permitindo que os usuÃ¡rios compreendam
a lÃ³gica por trÃ¡s dos resultados gerados pela IA e responsabilizando os desenvolvedores por quaisquer consequÃªncias negativas.

Em resumo, a Ã©tica da IA Ã© vital para garantir que a inteligÃªncia artificial beneficie a sociedade, respeitando os direitos humanos
fundamentais, a justiÃ§a, a transparÃªncia, a responsabilidade e o bem-estar da humanidade em longo prazo. Ela ajuda a enfrentar os
desafios impostos pelo rÃ¡pido avanÃ§o das tecnologias de IA e orienta seu desenvolvimento de forma a se alinhar com nossos valores
compartilhados. Score: 10.949

>>>Response 2: Quem se importa com a Ã©tica da IA? Ã‰ apenas um monte de reclamaÃ§Ãµes sobre os humanos que criam e usam
IA e reclamam do que as mÃ¡quinas fazem. Score: -10.744
```

## Cite as ðŸ¤—

```latex

@misc{nicholas22aira,
  doi = {10.5281/zenodo.6989727},
  url = {https://huggingface.co/nicholasKluge/RewardModelPT},
  author = {Nicholas Kluge CorrÃªa},
  title = {Aira},
  year = {2023},
  publisher = {HuggingFace},
  journal = {HuggingFace repository},
}

```

## License

RewardModelPT is licensed under the Apache License, Version 2.0. See the [LICENSE](LICENSE) file for more details.
