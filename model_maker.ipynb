{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Closed Domain Chatbot Maker\n",
    "\n",
    "![chatbot-gig](https://media2.giphy.com/media/S60CrN9iMxFlyp7uM8/giphy.gif)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bi lingual --> tags_bilingual.txt\n",
    "# pt --> tags_pt.txt\n",
    "# en --> tags_en.txt\n",
    "\n",
    "# 614 p\n",
    "\n",
    "with open('data\\\\tags_bilingual.txt', encoding='utf8') as file_in:\n",
    "    X = [' '.join(line.strip().split(' ')[:-1]) for line in file_in]\n",
    "with open('data\\\\tags_bilingual.txt', encoding='utf8') as file_in:\n",
    "    Y = [line.strip().split(' ')[-1] for line in file_in]\n",
    "\n",
    "from keras.layers import TextVectorization\n",
    "\n",
    "vocab_size = 2500 #2500 for bilingual or 1500 for english or portuguese\n",
    "embed_size = 256\n",
    "max_len = 10\n",
    "\n",
    "text_vectorization = TextVectorization(max_tokens=vocab_size, output_mode=\"int\", ngrams=2)\n",
    "text_vectorization.adapt(X)\n",
    "vocabulary = text_vectorization.get_vocabulary()\n",
    "inverse_vocab = dict(enumerate(vocabulary))\n",
    "\n",
    "with open(r'pre_trained_aira\\\\vocabulary_bilingual.txt', 'w') as fp:\n",
    "    for word in vocabulary:\n",
    "        fp.write(\"%s\\n\" % word)\n",
    "    \n",
    "encoded_X = text_vectorization(X)\n",
    "\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "encoded_X_padded = pad_sequences(encoded_X, maxlen=max_len, truncating='post')\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "one_hot_encoded_Y = to_categorical(Y)[:,1:]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(encoded_X_padded, one_hot_encoded_Y, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "inputs = tf.keras.Input(shape=(None,), dtype=\"int32\")\n",
    "\n",
    "embedded = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embed_size, mask_zero=True)(inputs)\n",
    "\n",
    "x = tf.keras.layers.Bidirectional(\n",
    "    tf.keras.layers.LSTM(128, return_sequences=True))(embedded)\n",
    "x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128))(x)\n",
    "x = tf.keras.layers.Dropout(0.8)(x)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(142, activation=\"softmax\")(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['categorical_accuracy'])\n",
    "\n",
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")\n",
    "model.summary()\n",
    "\n",
    "callbacks = [keras.callbacks.ModelCheckpoint(\"pre_trained_aira\\\\Aira_bilingual.keras\",\n",
    "                                                save_best_only=True,\n",
    "                                                monitor=\"val_loss\",\n",
    "                                                patience=10, \n",
    "                                                restore_best_weights=True)]\n",
    "\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          validation_split = 0.2,\n",
    "          epochs=100,\n",
    "          batch_size=8,\n",
    "          verbose=1,\n",
    "          callbacks=callbacks)\n",
    "\n",
    "model = keras.models.load_model(\"pre_trained_aira\\\\Aira_bilingual.keras\")\n",
    "test_loss_score, test_acc_score = model.evaluate(x_test, y_test)\n",
    "\n",
    "print(f'Final Loss: {round(test_loss_score, 1)}.')\n",
    "print(f'Final Performance: {round(test_acc_score * 100, 2)} %.')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "\n",
    "model = keras.models.load_model(\"pre_trained_aira\\\\Aira_bilingual.keras\")\n",
    "\n",
    "with open(r'pre_trained_aira\\\\vocabulary_bilingual.txt', 'r') as fp:\n",
    "    vocabulary = [line[:-1] for line in fp]\n",
    "\n",
    "with open('data\\\\answers_en.txt', encoding='utf8') as file_in:\n",
    "    answers = [line.strip() for line in file_in]\n",
    "\n",
    "from keras.layers import TextVectorization\n",
    "\n",
    "text_vectorization = TextVectorization(max_tokens=vocab_size, \n",
    "                                        output_mode=\"int\", \n",
    "                                        ngrams=2,\n",
    "                                        vocabulary=vocabulary)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questions: what is Interpretability?\n",
      "\n",
      "Encoded Sentence: [   3    7 1281    8 1975]\n",
      "\n",
      "Padded Encoded Sentence: [[   0    0    0    0    0    3    7 1281    8 1975]]\n",
      "\n",
      "Answers: Interpretability is the ability to explain or present the reasoning of an ML model in terms understandable to a human. [Confidence:  100.00 %]\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "text = '''what is Interpretability?'''\n",
    "#text = '''What is the problem of alignment?'''\n",
    "#text = '''O que é Interpretabilidade?'''\n",
    "#text = '''O que é o problema de Alinhamento?'''\n",
    "#text = '''What is Machine Learning?'''\n",
    "#text = '''O que é Ética das Virtudes?'''\n",
    "#text = '''What is your name?'''\n",
    "#text = '''Qual é o seu nome?'''\n",
    "#text = '''O que é SGD?'''\n",
    "#text = '''What is Stochastic Gradient Descent?'''\n",
    "\n",
    "print(f'Questions: {text}\\n')\n",
    "\n",
    "encoded_sentence = text_vectorization(text.lower().translate(str.maketrans('', '', string.punctuation)))\n",
    "print(f'Encoded Sentence: {encoded_sentence}\\n')\n",
    "\n",
    "encoded_sentence_padded = pad_sequences([encoded_sentence], maxlen=10, truncating='post')\n",
    "print(f'Padded Encoded Sentence: {encoded_sentence_padded}\\n')\n",
    "\n",
    "preds = model.predict(encoded_sentence_padded,verbose=0)[0]\n",
    "output = answers[np.argmax(preds)]\n",
    "print(f'Answers: {output} [Confidence: {max(preds) * 100: .2f} %]')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aca09746cf57686f00a55ae76e987247ecfb5dd0b3b2e2474d8dbbf0c5e3377e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
