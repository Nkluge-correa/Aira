{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Closed Domain Chatbot Maker\n",
    "\n",
    "![chatbot-gig](https://media2.giphy.com/media/S60CrN9iMxFlyp7uM8/giphy.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer, tokenizer_from_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tags.txt', encoding='utf8') as file_in:\n",
    "    X = []\n",
    "    Y = []\n",
    "    for line in file_in:\n",
    "        Y.append(line.strip().split(' ')[-1])\n",
    "        X.append(' '.join(line.strip().split(' ')[:-1]))\n",
    "Y = pd.get_dummies(pd.DataFrame(np.asarray(Y).astype(np.float)).rename(columns={0: 'label'})['label'], prefix='label_').values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 3000\n",
    "embed_size = 50\n",
    "max_len = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size,\n",
    "                      filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "                      lower=True,\n",
    "                      split=\" \",\n",
    "                      oov_token=\"<OOV>\")\n",
    "\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "training_sequences = tokenizer.texts_to_sequences(x_train)\n",
    "training_padded = pad_sequences(\n",
    "    training_sequences, maxlen=max_len, truncating='post')\n",
    "\n",
    "\n",
    "tokenizer_json = tokenizer.to_json()\n",
    "with io.open('pre_trained_aira\\\\aira_tokenizer.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(tokenizer_json, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bi-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  2.10.0\n",
      "Eager mode:  True\n",
      "GPU is available\n",
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_11 (InputLayer)       [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding_10 (Embedding)    (None, None, 50)          150000    \n",
      "                                                                 \n",
      " bidirectional_12 (Bidirecti  (None, None, 128)        58880     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_13 (Bidirecti  (None, 128)              98816     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 142)               18318     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 326,014\n",
      "Trainable params: 326,014\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\CWLINK\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\CWLINK\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\CWLINK\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\CWLINK\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 998, in train_step\n        return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\CWLINK\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1092, in compute_metrics\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"c:\\Users\\CWLINK\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 577, in update_state\n        self.build(y_pred, y_true)\n    File \"c:\\Users\\CWLINK\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 483, in build\n        self._metrics = tf.__internal__.nest.map_structure_up_to(\n    File \"c:\\Users\\CWLINK\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 631, in _get_metric_objects\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    File \"c:\\Users\\CWLINK\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 631, in <listcomp>\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    File \"c:\\Users\\CWLINK\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 650, in _get_metric_object\n        metric_obj = metrics_mod.get(metric)\n    File \"c:\\Users\\CWLINK\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\metrics\\__init__.py\", line 181, in get\n        return deserialize(str(identifier))\n    File \"c:\\Users\\CWLINK\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\metrics\\__init__.py\", line 136, in deserialize\n        return deserialize_keras_object(\n    File \"c:\\Users\\CWLINK\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\generic_utils.py\", line 769, in deserialize_keras_object\n        raise ValueError(\n\n    ValueError: Unknown metric function: sparse_categorical_accuracy . Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [22], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mGPU is\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mavailable\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mlist_physical_devices(\u001b[39m'\u001b[39m\u001b[39mGPU\u001b[39m\u001b[39m'\u001b[39m) \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mNOT AVAILABLE\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     20\u001b[0m model\u001b[39m.\u001b[39msummary()\n\u001b[1;32m---> 22\u001b[0m model\u001b[39m.\u001b[39mfit(training_padded,\n\u001b[0;32m     23\u001b[0m           y_train,\n\u001b[0;32m     24\u001b[0m           validation_split \u001b[39m=\u001b[39m \u001b[39m0.2\u001b[39m,\n\u001b[0;32m     25\u001b[0m           epochs\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m,\n\u001b[0;32m     26\u001b[0m           batch_size\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m,\n\u001b[0;32m     27\u001b[0m           verbose\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m     29\u001b[0m test_sequences \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mtexts_to_sequences(x_test)\n\u001b[0;32m     30\u001b[0m test_padded \u001b[39m=\u001b[39m pad_sequences(test_sequences, maxlen\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m, truncating\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\CWLINK\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file2b4ep7xe.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\CWLINK\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\CWLINK\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\CWLINK\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\CWLINK\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 998, in train_step\n        return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\CWLINK\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1092, in compute_metrics\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"c:\\Users\\CWLINK\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 577, in update_state\n        self.build(y_pred, y_true)\n    File \"c:\\Users\\CWLINK\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 483, in build\n        self._metrics = tf.__internal__.nest.map_structure_up_to(\n    File \"c:\\Users\\CWLINK\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 631, in _get_metric_objects\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    File \"c:\\Users\\CWLINK\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 631, in <listcomp>\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    File \"c:\\Users\\CWLINK\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 650, in _get_metric_object\n        metric_obj = metrics_mod.get(metric)\n    File \"c:\\Users\\CWLINK\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\metrics\\__init__.py\", line 181, in get\n        return deserialize(str(identifier))\n    File \"c:\\Users\\CWLINK\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\metrics\\__init__.py\", line 136, in deserialize\n        return deserialize_keras_object(\n    File \"c:\\Users\\CWLINK\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\generic_utils.py\", line 769, in deserialize_keras_object\n        raise ValueError(\n\n    ValueError: Unknown metric function: sparse_categorical_accuracy . Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(None,), dtype=\"int32\")\n",
    "x = tf.keras.layers.Embedding(input_dim=vocab_size,\n",
    "                              output_dim=embed_size,\n",
    "                              input_length=max_len)(inputs)\n",
    "\n",
    "x = tf.keras.layers.Bidirectional(\n",
    "    tf.keras.layers.LSTM(64, return_sequences=True))(x)\n",
    "x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64))(x)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(142, activation=\"softmax\")(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['sparse_categorical_accuracy '])\n",
    "\n",
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")\n",
    "model.summary()\n",
    "\n",
    "model.fit(training_padded,\n",
    "          y_train,\n",
    "          validation_split = 0.2,\n",
    "          epochs=50,\n",
    "          batch_size=5,\n",
    "          verbose=2)\n",
    "\n",
    "test_sequences = tokenizer.texts_to_sequences(x_test)\n",
    "test_padded = pad_sequences(test_sequences, maxlen=100, truncating='post')\n",
    "\n",
    "test_loss_score, test_acc_score = model.evaluate(test_padded, y_test)\n",
    "\n",
    "print(f'Final Loss: {round(test_loss_score, 2)}.')\n",
    "print(f'Final Performance: {round(test_acc_score * 100, 2)} %.')\n",
    "model.save('pre_trained_aira\\pre_trained_aira_lstm.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  2.10.0\n",
      "Eager mode:  True\n",
      "GPU is available\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_8 (InputLayer)           [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_7 (Embedding)        (None, 100, 50)      150000      ['input_8[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_24 (LayerN  (None, 100, 50)     100         ['embedding_7[0][0]']            \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_12 (Multi  (None, 100, 50)     311858      ['layer_normalization_24[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_26 (Dropout)           (None, 100, 50)      0           ['multi_head_attention_12[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_24 (TFOpL  (None, 100, 50)     0           ['dropout_26[0][0]',             \n",
      " ambda)                                                           'embedding_7[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_25 (LayerN  (None, 100, 50)     100         ['tf.__operators__.add_24[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_24 (Conv1D)             (None, 100, 4)       204         ['layer_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_27 (Dropout)           (None, 100, 4)       0           ['conv1d_24[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_25 (Conv1D)             (None, 100, 50)      250         ['dropout_27[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_25 (TFOpL  (None, 100, 50)     0           ['conv1d_25[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_24[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_26 (LayerN  (None, 100, 50)     100         ['tf.__operators__.add_25[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_13 (Multi  (None, 100, 50)     311858      ['layer_normalization_26[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_28 (Dropout)           (None, 100, 50)      0           ['multi_head_attention_13[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_26 (TFOpL  (None, 100, 50)     0           ['dropout_28[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_25[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_27 (LayerN  (None, 100, 50)     100         ['tf.__operators__.add_26[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_26 (Conv1D)             (None, 100, 4)       204         ['layer_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_29 (Dropout)           (None, 100, 4)       0           ['conv1d_26[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_27 (Conv1D)             (None, 100, 50)      250         ['dropout_29[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_27 (TFOpL  (None, 100, 50)     0           ['conv1d_27[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_26[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_28 (LayerN  (None, 100, 50)     100         ['tf.__operators__.add_27[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_14 (Multi  (None, 100, 50)     311858      ['layer_normalization_28[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_30 (Dropout)           (None, 100, 50)      0           ['multi_head_attention_14[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_28 (TFOpL  (None, 100, 50)     0           ['dropout_30[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_27[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_29 (LayerN  (None, 100, 50)     100         ['tf.__operators__.add_28[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_28 (Conv1D)             (None, 100, 4)       204         ['layer_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_31 (Dropout)           (None, 100, 4)       0           ['conv1d_28[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_29 (Conv1D)             (None, 100, 50)      250         ['dropout_31[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_29 (TFOpL  (None, 100, 50)     0           ['conv1d_29[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_28[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_30 (LayerN  (None, 100, 50)     100         ['tf.__operators__.add_29[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_15 (Multi  (None, 100, 50)     311858      ['layer_normalization_30[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_32 (Dropout)           (None, 100, 50)      0           ['multi_head_attention_15[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_30 (TFOpL  (None, 100, 50)     0           ['dropout_32[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_29[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_31 (LayerN  (None, 100, 50)     100         ['tf.__operators__.add_30[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_30 (Conv1D)             (None, 100, 4)       204         ['layer_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_33 (Dropout)           (None, 100, 4)       0           ['conv1d_30[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_31 (Conv1D)             (None, 100, 50)      250         ['dropout_33[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_31 (TFOpL  (None, 100, 50)     0           ['conv1d_31[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_30[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_32 (LayerN  (None, 100, 50)     100         ['tf.__operators__.add_31[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_16 (Multi  (None, 100, 50)     311858      ['layer_normalization_32[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_34 (Dropout)           (None, 100, 50)      0           ['multi_head_attention_16[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_32 (TFOpL  (None, 100, 50)     0           ['dropout_34[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_31[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_33 (LayerN  (None, 100, 50)     100         ['tf.__operators__.add_32[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_32 (Conv1D)             (None, 100, 4)       204         ['layer_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_35 (Dropout)           (None, 100, 4)       0           ['conv1d_32[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_33 (Conv1D)             (None, 100, 50)      250         ['dropout_35[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_33 (TFOpL  (None, 100, 50)     0           ['conv1d_33[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_32[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_34 (LayerN  (None, 100, 50)     100         ['tf.__operators__.add_33[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_17 (Multi  (None, 100, 50)     311858      ['layer_normalization_34[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_36 (Dropout)           (None, 100, 50)      0           ['multi_head_attention_17[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_34 (TFOpL  (None, 100, 50)     0           ['dropout_36[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_33[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_35 (LayerN  (None, 100, 50)     100         ['tf.__operators__.add_34[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_34 (Conv1D)             (None, 100, 4)       204         ['layer_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_37 (Dropout)           (None, 100, 4)       0           ['conv1d_34[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_35 (Conv1D)             (None, 100, 50)      250         ['dropout_37[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_35 (TFOpL  (None, 100, 50)     0           ['conv1d_35[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_34[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_2 (Gl  (None, 100)         0           ['tf.__operators__.add_35[0][0]']\n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 128)          12928       ['global_average_pooling1d_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_38 (Dropout)           (None, 128)          0           ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 142)          18318       ['dropout_38[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,056,318\n",
      "Trainable params: 2,056,318\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "249/249 [==============================] - 21s 69ms/step - loss: 5.0259 - categorical_accuracy: 0.0097 - val_loss: 5.2644 - val_categorical_accuracy: 0.0096\n",
      "Epoch 2/100\n",
      "249/249 [==============================] - 16s 66ms/step - loss: 4.9897 - categorical_accuracy: 0.0129 - val_loss: 5.0185 - val_categorical_accuracy: 0.0129\n",
      "Epoch 3/100\n",
      "249/249 [==============================] - 16s 66ms/step - loss: 4.9584 - categorical_accuracy: 0.0129 - val_loss: 4.9633 - val_categorical_accuracy: 0.0064\n",
      "Epoch 4/100\n",
      "249/249 [==============================] - 17s 66ms/step - loss: 4.9608 - categorical_accuracy: 0.0137 - val_loss: 5.0696 - val_categorical_accuracy: 0.0129\n",
      "Epoch 5/100\n",
      "249/249 [==============================] - 17s 66ms/step - loss: 4.9306 - categorical_accuracy: 0.0113 - val_loss: 5.0865 - val_categorical_accuracy: 0.0096\n",
      "Epoch 6/100\n",
      "249/249 [==============================] - 17s 66ms/step - loss: 4.8896 - categorical_accuracy: 0.0242 - val_loss: 4.9669 - val_categorical_accuracy: 0.0161\n",
      "Epoch 7/100\n",
      "249/249 [==============================] - 17s 67ms/step - loss: 4.7684 - categorical_accuracy: 0.0242 - val_loss: 4.9445 - val_categorical_accuracy: 0.0289\n",
      "Epoch 8/100\n",
      "249/249 [==============================] - 17s 67ms/step - loss: 4.7528 - categorical_accuracy: 0.0258 - val_loss: 4.9366 - val_categorical_accuracy: 0.0161\n",
      "Epoch 9/100\n",
      "249/249 [==============================] - 17s 68ms/step - loss: 4.6559 - categorical_accuracy: 0.0225 - val_loss: 4.8767 - val_categorical_accuracy: 0.0193\n",
      "Epoch 10/100\n",
      "249/249 [==============================] - 17s 67ms/step - loss: 4.5289 - categorical_accuracy: 0.0250 - val_loss: 4.7666 - val_categorical_accuracy: 0.0129\n",
      "Epoch 11/100\n",
      "249/249 [==============================] - 17s 67ms/step - loss: 4.3937 - categorical_accuracy: 0.0306 - val_loss: 4.6052 - val_categorical_accuracy: 0.0322\n",
      "Epoch 12/100\n",
      "249/249 [==============================] - 17s 67ms/step - loss: 4.3050 - categorical_accuracy: 0.0491 - val_loss: 4.6320 - val_categorical_accuracy: 0.0450\n",
      "Epoch 13/100\n",
      "249/249 [==============================] - 17s 67ms/step - loss: 4.1941 - categorical_accuracy: 0.0596 - val_loss: 4.4073 - val_categorical_accuracy: 0.0707\n",
      "Epoch 14/100\n",
      "249/249 [==============================] - 17s 67ms/step - loss: 4.0871 - categorical_accuracy: 0.0539 - val_loss: 4.5151 - val_categorical_accuracy: 0.0354\n",
      "Epoch 15/100\n",
      "249/249 [==============================] - 17s 67ms/step - loss: 4.0541 - categorical_accuracy: 0.0604 - val_loss: 4.3113 - val_categorical_accuracy: 0.0547\n",
      "Epoch 16/100\n",
      "249/249 [==============================] - 17s 68ms/step - loss: 3.9326 - categorical_accuracy: 0.0757 - val_loss: 4.2963 - val_categorical_accuracy: 0.0740\n",
      "Epoch 17/100\n",
      "249/249 [==============================] - 17s 67ms/step - loss: 3.8151 - categorical_accuracy: 0.0958 - val_loss: 4.2462 - val_categorical_accuracy: 0.0772\n",
      "Epoch 18/100\n",
      "249/249 [==============================] - 17s 68ms/step - loss: 3.7265 - categorical_accuracy: 0.1031 - val_loss: 4.2772 - val_categorical_accuracy: 0.0675\n",
      "Epoch 19/100\n",
      "249/249 [==============================] - 17s 67ms/step - loss: 3.6474 - categorical_accuracy: 0.1127 - val_loss: 4.1848 - val_categorical_accuracy: 0.0932\n",
      "Epoch 20/100\n",
      "249/249 [==============================] - 17s 68ms/step - loss: 3.5405 - categorical_accuracy: 0.1329 - val_loss: 4.1407 - val_categorical_accuracy: 0.1029\n",
      "Epoch 21/100\n",
      "249/249 [==============================] - 17s 67ms/step - loss: 3.5248 - categorical_accuracy: 0.1216 - val_loss: 4.1009 - val_categorical_accuracy: 0.0997\n",
      "Epoch 22/100\n",
      "249/249 [==============================] - 17s 67ms/step - loss: 3.4022 - categorical_accuracy: 0.1393 - val_loss: 3.9954 - val_categorical_accuracy: 0.1029\n",
      "Epoch 23/100\n",
      "249/249 [==============================] - 17s 67ms/step - loss: 3.3252 - categorical_accuracy: 0.1449 - val_loss: 4.0488 - val_categorical_accuracy: 0.1061\n",
      "Epoch 24/100\n",
      "249/249 [==============================] - 17s 67ms/step - loss: 3.2520 - categorical_accuracy: 0.1626 - val_loss: 3.9121 - val_categorical_accuracy: 0.1286\n",
      "Epoch 25/100\n",
      "249/249 [==============================] - 17s 67ms/step - loss: 3.1739 - categorical_accuracy: 0.1618 - val_loss: 3.9419 - val_categorical_accuracy: 0.1576\n",
      "Epoch 26/100\n",
      "249/249 [==============================] - 17s 67ms/step - loss: 3.0137 - categorical_accuracy: 0.1836 - val_loss: 3.8587 - val_categorical_accuracy: 0.1576\n",
      "Epoch 27/100\n",
      "249/249 [==============================] - 17s 67ms/step - loss: 2.9799 - categorical_accuracy: 0.2077 - val_loss: 3.8827 - val_categorical_accuracy: 0.1543\n",
      "Epoch 28/100\n",
      "249/249 [==============================] - 17s 67ms/step - loss: 2.9098 - categorical_accuracy: 0.2061 - val_loss: 3.9683 - val_categorical_accuracy: 0.1704\n",
      "Epoch 29/100\n",
      "249/249 [==============================] - 17s 67ms/step - loss: 2.8187 - categorical_accuracy: 0.2262 - val_loss: 3.9714 - val_categorical_accuracy: 0.1736\n",
      "Epoch 30/100\n",
      "249/249 [==============================] - 17s 67ms/step - loss: 2.8097 - categorical_accuracy: 0.2367 - val_loss: 3.8817 - val_categorical_accuracy: 0.1897\n",
      "Epoch 31/100\n",
      "249/249 [==============================] - 17s 67ms/step - loss: 2.7989 - categorical_accuracy: 0.2375 - val_loss: 3.8479 - val_categorical_accuracy: 0.1672\n",
      "Epoch 32/100\n",
      "249/249 [==============================] - 17s 67ms/step - loss: 2.7170 - categorical_accuracy: 0.2464 - val_loss: 3.8328 - val_categorical_accuracy: 0.2186\n",
      "Epoch 33/100\n",
      "249/249 [==============================] - 17s 67ms/step - loss: 2.5949 - categorical_accuracy: 0.2746 - val_loss: 4.1362 - val_categorical_accuracy: 0.1833\n",
      "Epoch 34/100\n",
      "249/249 [==============================] - 17s 67ms/step - loss: 2.5578 - categorical_accuracy: 0.2915 - val_loss: 4.0037 - val_categorical_accuracy: 0.1801\n",
      "Epoch 35/100\n",
      "249/249 [==============================] - 17s 67ms/step - loss: 2.5264 - categorical_accuracy: 0.2842 - val_loss: 3.8037 - val_categorical_accuracy: 0.2476\n",
      "Epoch 36/100\n",
      "249/249 [==============================] - 17s 67ms/step - loss: 2.4818 - categorical_accuracy: 0.2971 - val_loss: 3.8374 - val_categorical_accuracy: 0.2186\n",
      "Epoch 37/100\n",
      "249/249 [==============================] - 17s 67ms/step - loss: 2.4352 - categorical_accuracy: 0.3164 - val_loss: 3.8537 - val_categorical_accuracy: 0.2379\n",
      "Epoch 38/100\n",
      "249/249 [==============================] - 17s 67ms/step - loss: 2.4262 - categorical_accuracy: 0.3035 - val_loss: 3.7971 - val_categorical_accuracy: 0.2283\n",
      "Epoch 39/100\n",
      "249/249 [==============================] - 17s 68ms/step - loss: 2.3647 - categorical_accuracy: 0.3124 - val_loss: 3.8231 - val_categorical_accuracy: 0.2251\n",
      "Epoch 40/100\n",
      "249/249 [==============================] - 17s 68ms/step - loss: 2.3298 - categorical_accuracy: 0.3237 - val_loss: 3.8365 - val_categorical_accuracy: 0.2669\n",
      "Epoch 41/100\n",
      "249/249 [==============================] - 17s 68ms/step - loss: 2.3024 - categorical_accuracy: 0.3414 - val_loss: 3.8251 - val_categorical_accuracy: 0.2251\n",
      "Epoch 42/100\n",
      "249/249 [==============================] - 17s 68ms/step - loss: 2.1987 - categorical_accuracy: 0.3494 - val_loss: 3.9986 - val_categorical_accuracy: 0.2251\n",
      "Epoch 43/100\n",
      "249/249 [==============================] - 17s 67ms/step - loss: 2.1758 - categorical_accuracy: 0.3527 - val_loss: 4.0766 - val_categorical_accuracy: 0.2347\n",
      "Epoch 44/100\n",
      "249/249 [==============================] - 17s 68ms/step - loss: 2.1389 - categorical_accuracy: 0.3792 - val_loss: 3.9953 - val_categorical_accuracy: 0.2540\n",
      "Epoch 45/100\n",
      "249/249 [==============================] - 17s 67ms/step - loss: 2.1450 - categorical_accuracy: 0.3671 - val_loss: 3.8862 - val_categorical_accuracy: 0.2733\n",
      "Epoch 46/100\n",
      "249/249 [==============================] - 17s 67ms/step - loss: 2.1738 - categorical_accuracy: 0.3833 - val_loss: 3.9473 - val_categorical_accuracy: 0.2508\n",
      "Epoch 47/100\n",
      "249/249 [==============================] - 17s 67ms/step - loss: 2.0545 - categorical_accuracy: 0.3913 - val_loss: 4.2270 - val_categorical_accuracy: 0.2605\n",
      "Epoch 48/100\n",
      "249/249 [==============================] - 17s 66ms/step - loss: 1.9759 - categorical_accuracy: 0.4058 - val_loss: 3.9843 - val_categorical_accuracy: 0.2894\n",
      "Epoch 49/100\n",
      "249/249 [==============================] - 17s 68ms/step - loss: 2.0171 - categorical_accuracy: 0.4155 - val_loss: 4.0668 - val_categorical_accuracy: 0.2733\n",
      "Epoch 50/100\n",
      "249/249 [==============================] - 17s 68ms/step - loss: 2.0702 - categorical_accuracy: 0.3704 - val_loss: 3.9850 - val_categorical_accuracy: 0.2283\n",
      "Epoch 51/100\n",
      "249/249 [==============================] - 17s 68ms/step - loss: 1.9826 - categorical_accuracy: 0.4130 - val_loss: 4.0851 - val_categorical_accuracy: 0.2605\n",
      "Epoch 52/100\n",
      "249/249 [==============================] - 17s 68ms/step - loss: 1.9211 - categorical_accuracy: 0.4243 - val_loss: 4.1718 - val_categorical_accuracy: 0.2508\n",
      "Epoch 53/100\n",
      "249/249 [==============================] - 17s 68ms/step - loss: 1.8965 - categorical_accuracy: 0.4211 - val_loss: 4.1701 - val_categorical_accuracy: 0.2733\n",
      "Epoch 54/100\n",
      "249/249 [==============================] - 17s 69ms/step - loss: 1.8583 - categorical_accuracy: 0.4332 - val_loss: 4.1477 - val_categorical_accuracy: 0.2830\n",
      "Epoch 55/100\n",
      "249/249 [==============================] - 17s 68ms/step - loss: 1.8451 - categorical_accuracy: 0.4428 - val_loss: 4.3808 - val_categorical_accuracy: 0.2733\n",
      "Epoch 56/100\n",
      "249/249 [==============================] - 17s 68ms/step - loss: 1.8615 - categorical_accuracy: 0.4348 - val_loss: 4.1799 - val_categorical_accuracy: 0.2637\n",
      "Epoch 57/100\n",
      "249/249 [==============================] - 17s 67ms/step - loss: 1.9284 - categorical_accuracy: 0.4219 - val_loss: 4.2081 - val_categorical_accuracy: 0.2572\n",
      "Epoch 58/100\n",
      "249/249 [==============================] - 17s 68ms/step - loss: 1.8313 - categorical_accuracy: 0.4565 - val_loss: 4.2966 - val_categorical_accuracy: 0.2701\n",
      "Epoch 59/100\n",
      "249/249 [==============================] - 17s 68ms/step - loss: 1.8312 - categorical_accuracy: 0.4533 - val_loss: 4.5772 - val_categorical_accuracy: 0.2283\n",
      "Epoch 60/100\n",
      "249/249 [==============================] - 17s 68ms/step - loss: 1.7469 - categorical_accuracy: 0.4726 - val_loss: 4.5492 - val_categorical_accuracy: 0.2540\n",
      "Epoch 61/100\n",
      "249/249 [==============================] - 17s 67ms/step - loss: 1.7615 - categorical_accuracy: 0.4718 - val_loss: 4.8166 - val_categorical_accuracy: 0.2572\n",
      "Epoch 62/100\n",
      "249/249 [==============================] - 17s 67ms/step - loss: 1.7845 - categorical_accuracy: 0.4501 - val_loss: 4.3636 - val_categorical_accuracy: 0.2637\n",
      "Epoch 63/100\n",
      "249/249 [==============================] - 17s 68ms/step - loss: 1.6899 - categorical_accuracy: 0.4839 - val_loss: 4.3162 - val_categorical_accuracy: 0.3055\n",
      "Epoch 64/100\n",
      "249/249 [==============================] - 17s 67ms/step - loss: 1.6769 - categorical_accuracy: 0.4718 - val_loss: 4.3311 - val_categorical_accuracy: 0.2862\n",
      "Epoch 65/100\n",
      "249/249 [==============================] - 17s 67ms/step - loss: 1.6531 - categorical_accuracy: 0.4944 - val_loss: 4.5307 - val_categorical_accuracy: 0.2733\n",
      "Epoch 66/100\n",
      "249/249 [==============================] - 17s 67ms/step - loss: 1.6935 - categorical_accuracy: 0.4742 - val_loss: 4.5971 - val_categorical_accuracy: 0.2733\n",
      "Epoch 67/100\n",
      "249/249 [==============================] - 17s 67ms/step - loss: 1.6980 - categorical_accuracy: 0.4831 - val_loss: 4.6862 - val_categorical_accuracy: 0.2540\n",
      "Epoch 68/100\n",
      "249/249 [==============================] - 17s 68ms/step - loss: 1.6474 - categorical_accuracy: 0.4936 - val_loss: 4.6902 - val_categorical_accuracy: 0.2765\n",
      "Epoch 69/100\n",
      "249/249 [==============================] - 17s 68ms/step - loss: 1.5761 - categorical_accuracy: 0.5177 - val_loss: 4.9179 - val_categorical_accuracy: 0.2797\n",
      "Epoch 70/100\n",
      "249/249 [==============================] - 17s 68ms/step - loss: 1.6056 - categorical_accuracy: 0.5008 - val_loss: 4.6944 - val_categorical_accuracy: 0.2797\n",
      "Epoch 71/100\n",
      "249/249 [==============================] - 17s 68ms/step - loss: 1.5470 - categorical_accuracy: 0.5008 - val_loss: 5.1064 - val_categorical_accuracy: 0.2765\n",
      "Epoch 72/100\n",
      "249/249 [==============================] - 17s 69ms/step - loss: 1.5270 - categorical_accuracy: 0.5193 - val_loss: 5.3281 - val_categorical_accuracy: 0.1961\n",
      "Epoch 73/100\n",
      "249/249 [==============================] - 17s 69ms/step - loss: 1.6247 - categorical_accuracy: 0.4928 - val_loss: 4.7330 - val_categorical_accuracy: 0.2862\n",
      "Epoch 74/100\n",
      "249/249 [==============================] - 17s 68ms/step - loss: 1.5694 - categorical_accuracy: 0.5314 - val_loss: 5.1100 - val_categorical_accuracy: 0.2958\n",
      "Epoch 75/100\n",
      "249/249 [==============================] - 17s 68ms/step - loss: 1.4705 - categorical_accuracy: 0.5531 - val_loss: 5.0327 - val_categorical_accuracy: 0.3087\n",
      "Epoch 76/100\n",
      "249/249 [==============================] - 17s 68ms/step - loss: 1.4934 - categorical_accuracy: 0.5290 - val_loss: 5.1048 - val_categorical_accuracy: 0.2862\n",
      "Epoch 77/100\n",
      "249/249 [==============================] - 17s 67ms/step - loss: 1.4816 - categorical_accuracy: 0.5330 - val_loss: 5.0323 - val_categorical_accuracy: 0.2669\n",
      "Epoch 78/100\n",
      "249/249 [==============================] - 16s 66ms/step - loss: 1.5379 - categorical_accuracy: 0.5330 - val_loss: 4.5835 - val_categorical_accuracy: 0.2958\n",
      "Epoch 79/100\n",
      "249/249 [==============================] - 17s 67ms/step - loss: 1.4805 - categorical_accuracy: 0.5346 - val_loss: 5.0658 - val_categorical_accuracy: 0.3087\n",
      "Epoch 80/100\n",
      "249/249 [==============================] - 17s 68ms/step - loss: 1.5190 - categorical_accuracy: 0.5419 - val_loss: 4.7654 - val_categorical_accuracy: 0.2830\n",
      "Epoch 81/100\n",
      "249/249 [==============================] - 17s 68ms/step - loss: 1.4595 - categorical_accuracy: 0.5459 - val_loss: 5.0092 - val_categorical_accuracy: 0.2701\n",
      "Epoch 82/100\n",
      "249/249 [==============================] - 17s 68ms/step - loss: 1.3924 - categorical_accuracy: 0.5709 - val_loss: 5.0593 - val_categorical_accuracy: 0.2894\n",
      "Epoch 83/100\n",
      "249/249 [==============================] - 17s 67ms/step - loss: 1.5020 - categorical_accuracy: 0.5435 - val_loss: 5.2526 - val_categorical_accuracy: 0.2637\n",
      "Epoch 84/100\n",
      "249/249 [==============================] - 17s 68ms/step - loss: 1.4413 - categorical_accuracy: 0.5676 - val_loss: 5.2330 - val_categorical_accuracy: 0.3119\n",
      "Epoch 85/100\n",
      "249/249 [==============================] - 17s 67ms/step - loss: 1.4667 - categorical_accuracy: 0.5644 - val_loss: 5.0211 - val_categorical_accuracy: 0.2990\n",
      "Epoch 86/100\n",
      "249/249 [==============================] - 17s 67ms/step - loss: 1.4667 - categorical_accuracy: 0.5435 - val_loss: 4.9794 - val_categorical_accuracy: 0.3119\n",
      "Epoch 87/100\n",
      "249/249 [==============================] - 17s 67ms/step - loss: 1.3813 - categorical_accuracy: 0.5572 - val_loss: 5.1908 - val_categorical_accuracy: 0.3183\n",
      "Epoch 88/100\n",
      "249/249 [==============================] - 17s 67ms/step - loss: 1.3373 - categorical_accuracy: 0.5717 - val_loss: 5.3565 - val_categorical_accuracy: 0.2926\n",
      "Epoch 89/100\n",
      "249/249 [==============================] - 17s 67ms/step - loss: 1.3865 - categorical_accuracy: 0.5660 - val_loss: 5.3619 - val_categorical_accuracy: 0.2990\n",
      "Epoch 90/100\n",
      "249/249 [==============================] - 17s 67ms/step - loss: 1.2842 - categorical_accuracy: 0.6063 - val_loss: 5.3799 - val_categorical_accuracy: 0.3151\n",
      "Epoch 91/100\n",
      "249/249 [==============================] - 17s 67ms/step - loss: 1.3449 - categorical_accuracy: 0.5789 - val_loss: 5.6120 - val_categorical_accuracy: 0.2894\n",
      "Epoch 92/100\n",
      "249/249 [==============================] - 17s 67ms/step - loss: 1.2913 - categorical_accuracy: 0.5886 - val_loss: 5.8605 - val_categorical_accuracy: 0.2797\n",
      "Epoch 93/100\n",
      "249/249 [==============================] - 17s 67ms/step - loss: 1.4201 - categorical_accuracy: 0.5934 - val_loss: 5.3661 - val_categorical_accuracy: 0.3215\n",
      "Epoch 94/100\n",
      "249/249 [==============================] - 17s 67ms/step - loss: 1.3952 - categorical_accuracy: 0.5596 - val_loss: 5.2852 - val_categorical_accuracy: 0.3151\n",
      "Epoch 95/100\n",
      "249/249 [==============================] - 17s 67ms/step - loss: 1.3224 - categorical_accuracy: 0.5741 - val_loss: 5.6662 - val_categorical_accuracy: 0.3215\n",
      "Epoch 96/100\n",
      "249/249 [==============================] - 17s 67ms/step - loss: 1.2332 - categorical_accuracy: 0.6192 - val_loss: 5.5561 - val_categorical_accuracy: 0.3248\n",
      "Epoch 97/100\n",
      "249/249 [==============================] - 16s 66ms/step - loss: 1.3201 - categorical_accuracy: 0.6055 - val_loss: 5.6537 - val_categorical_accuracy: 0.3087\n",
      "Epoch 98/100\n",
      "249/249 [==============================] - 17s 67ms/step - loss: 1.3313 - categorical_accuracy: 0.5757 - val_loss: 5.8519 - val_categorical_accuracy: 0.2797\n",
      "Epoch 99/100\n",
      "249/249 [==============================] - 17s 67ms/step - loss: 1.3093 - categorical_accuracy: 0.5942 - val_loss: 5.5834 - val_categorical_accuracy: 0.3183\n",
      "Epoch 100/100\n",
      "249/249 [==============================] - 17s 67ms/step - loss: 1.3118 - categorical_accuracy: 0.5974 - val_loss: 5.7209 - val_categorical_accuracy: 0.3055\n",
      "13/13 [==============================] - 1s 91ms/step - loss: 5.1984 - categorical_accuracy: 0.3522\n",
      "Final Loss: 5.2.\n",
      "Final Performance: 35.22 %.\n"
     ]
    }
   ],
   "source": [
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Normalization and Attention\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = layers.MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "    )(x, x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    return x + res\n",
    "\n",
    "def build_model(\n",
    "    input_shape,\n",
    "    head_size,\n",
    "    num_heads,\n",
    "    ff_dim,\n",
    "    num_transformer_blocks,\n",
    "    mlp_units,\n",
    "    dropout=0,\n",
    "    mlp_dropout=0,\n",
    "):\n",
    "    vocab_size = 3000\n",
    "    embed_size = 50\n",
    "    max_len = 100\n",
    "    inputs = tf.keras.Input(shape=input_shape, dtype=\"int32\")\n",
    "    x = tf.keras.layers.Embedding(input_dim=vocab_size,\n",
    "                              output_dim=embed_size,\n",
    "                              input_length=max_len)(inputs)\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
    "    for dim in mlp_units:\n",
    "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(mlp_dropout)(x)\n",
    "    outputs = layers.Dense(142, activation=\"softmax\")(x)\n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "input_shape = (training_padded.shape[1])\n",
    "\n",
    "model = build_model(\n",
    "    input_shape,\n",
    "    head_size=256,\n",
    "    num_heads=6,\n",
    "    ff_dim=4,\n",
    "    num_transformer_blocks=6,\n",
    "    mlp_units=[128],\n",
    "    mlp_dropout=0.4,\n",
    "    dropout=0.2,\n",
    ")\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")\n",
    "model.summary()\n",
    "\n",
    "model.fit(training_padded,\n",
    "          y_train,\n",
    "          validation_split = 0.2,\n",
    "          epochs=100,\n",
    "          batch_size=5,\n",
    "          verbose=1)\n",
    "\n",
    "test_sequences = tokenizer.texts_to_sequences(x_test)\n",
    "test_padded = pad_sequences(test_sequences, maxlen=100, truncating='post')\n",
    "\n",
    "test_loss_score, test_acc_score = model.evaluate(test_padded, y_test)\n",
    "\n",
    "print(f'Final Loss: {round(test_loss_score, 2)}.')\n",
    "print(f'Final Performance: {round(test_acc_score * 100, 2)} %.')\n",
    "model.save('pre_trained_aira\\pre_trained_aira_transformer.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aca09746cf57686f00a55ae76e987247ecfb5dd0b3b2e2474d8dbbf0c5e3377e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
