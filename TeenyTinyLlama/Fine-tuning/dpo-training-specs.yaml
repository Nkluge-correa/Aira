model_args:
  base_model: "nicholasKluge/TeenyTinyLlama-160m"
  model_ref: "nicholasKluge/TeenyTinyLlama-160m"
  model_id: "160m"
  boi_token: "<instruction>"
  eoi_token: "</instruction>"
  cache_dir: null
data_args:
    dataset_name: "nicholasKluge/reward-aira-dataset"
    dataset_split: "portuguese"
    validation_split_percentage: null
    streaming: false
    max_prompt_length: 500
    max_length: 1500
    sanity_check: false
training_args:
  output_dir: "checkpoints"
  do_eval: false
  evaluation_strategy: "no"
  save_strategy: "steps"
  logging_strategy: "steps"
  logging_steps: 200
  max_steps: 2400
  save_steps: 200
  per_device_train_batch_size: 8
  per_device_eval_batch_size: 8
  gradient_accumulation_steps: 1
  gradient_checkpointing: false
  optim: "adamw_torch"
  learning_rate: 0.00001
  lr_scheduler_type: "cosine"
  warmup_steps: 200
  hub_token: null
  push_to_hub: true
  hub_model_id: "nicholasKluge/TeenyTinyLlama-160m-Chat-DPO"
extra_args:
  logger_name: "TeenyTinyLlama"
  wandb_token: null
  beta: 0.8