config_name: "gpt2"
list_of_datasets:
  - ["wikitext", "wikitext-2-raw-v1"]
  - ["bookcorpus", "plain_text"]
logger_name: "gpt2-logger"
max_steps: 1000000
model_name_or_path: "gpt2"
language_modeling_task: "clm"
train_from_scratch: true
train_new_tokenizer: false
tokenizer_vocab_size: 52000
do_train: true
do_eval: false
eval_steps: 0.1
model_type: "gpt2"
output_dir: "tmp_gpt2"
per_device_eval_batch_size: 8
per_device_train_batch_size: 8
no_cuda: false
save_total_limit: 5
tokenizer_name: "gpt2"
hub_model_id: "nicholasKluge/gpt2-test"
hub_token: null
